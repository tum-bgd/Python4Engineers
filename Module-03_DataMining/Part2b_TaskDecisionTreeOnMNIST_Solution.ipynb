{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e9edda3-6da8-4be9-a52a-247bb2ccd265",
   "metadata": {},
   "source": [
    "# Task: Decision Tree on the MNIST dataset\n",
    "\n",
    "Mimic the steps in the iris example. Use a decision tree again to train a classification model to identify handwritten digits using the popular MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fabb3e0-7938-48b5-a271-baca0c9aef1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95fcadd-1dec-4c64-8984-0dc6cb2f1c8a",
   "metadata": {},
   "source": [
    "## Data Acquisition and Preprocessing\n",
    "The MNIST data is acquired from openml, but in order not to go out to the Internet frequently, we download it and bring it into our preferred form of a variable X and a variable y and save it in well-named numpy files. If these files exist, we just load the preprocessed data from disk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c329d8-b66d-4912-93d8-8f3600657891",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = None \n",
    "y = None\n",
    "if not os.path.exists(\"mnist_X.npy\"):\n",
    "    print(\"Acquiring and preprocessing\")\n",
    "    mnist = fetch_openml('mnist_784')\n",
    "    X = mnist.data.to_numpy().astype(np.uint8) # these have been grayscale in floating point, now 0 .. 255\n",
    "    y = [int(x) for x in mnist.target.to_numpy()] # targets have been strings\n",
    "    np.save(\"mnist_X.npy\",X )\n",
    "    np.save(\"mnist_y.npy\",y )\n",
    "else:\n",
    "    print(\"Using cache. Delete mnist_*.npy to reacquire\")\n",
    "    X=np.load(\"mnist_X.npy\")\n",
    "    y = np.load(\"mnist_y.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d003fac-5cae-424a-9f56-cc66c09022b2",
   "metadata": {},
   "source": [
    "## Show a few random images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87def5ba-9b79-4bef-a8bf-dfcb77a4dbf1",
   "metadata": {},
   "source": [
    "Be wise. Your data loading code will be wrong in the beginning. Whenever you train a model, at least glimpse on the soundness of the model input. A random plot is a good start. Here, the title is the class and the image is just the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c5c162-7abb-485b-bf78-cd3a66f3fca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show a random image\n",
    "vis = np.random.choice(range(X.shape[0]), size=6)\n",
    "print(vis)\n",
    "\n",
    "for i,j in enumerate(vis):\n",
    "    plt.subplot(1,6,i+1)\n",
    "    plt.imshow(X[j].reshape(28,28),cmap = plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title(y[j])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93775cc-1b52-4f19-9e05-543addeae1b9",
   "metadata": {},
   "source": [
    "## Train Test Split\n",
    "Data Mining requires a training set to find model paramaeters and a test set to estimate performance on unseen data. These two datasets can be created for MNIST by using just random splits as provided by `train_test_split` in skicit-learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b665f83-a8d8-4458-82e3-b72040a732e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)  # 70% data for training, 30% data for testing\n",
    "print(\"# data points for training:\", len(X_train))\n",
    "print(\"# data points for training:\", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9270a58c-58d3-4141-9e37-797af200a875",
   "metadata": {},
   "source": [
    "## Train the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748fb5c1-7514-4fe2-8205-f287e0be5534",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2880e3-2ba4-4d34-b94f-c7eb40e7b18f",
   "metadata": {},
   "source": [
    "# Evaluate the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea36eab-9de6-4130-83ab-8a214f5029d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get estimation from the trained model (dtc)\n",
    "pred_train = dtc.predict(X_train)\n",
    "pred_test = dtc.predict(X_test)\n",
    "# obtain accuracy\n",
    "print(classification_report(pred_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1c810e-23d7-4fd7-ab55-8222b7eac2ba",
   "metadata": {},
   "source": [
    "# Conclude\n",
    "This seems tos how that a Decision tree is reaching 87% on average, quite good, but not good enough. This is where Deep Learning will bring a real boost."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
